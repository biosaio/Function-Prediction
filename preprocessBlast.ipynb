{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPgb4QO/DcfcsCKpF6LlL94"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YHrAXYbRJnLC","executionInfo":{"status":"ok","timestamp":1737211110827,"user_tz":-60,"elapsed":1656,"user":{"displayName":"Flavio Agostini","userId":"01513805401167554788"}},"outputId":"8ad92b10-425a-4a3f-983b-d089f76e48ea"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Device: cpu\n"]}],"source":["\n","import sys\n","import os\n","import logging\n","import yaml\n","import torch\n","from google.colab import drive\n","import pandas as pd\n","import numpy as np\n","import random\n","\n","drive.mount('/content/drive')\n","\n","PROJECT_DIR = \"/content/drive/MyDrive/BiologicalData/progetto/biological_data_pfp/biological_data_pfp\"\n","SRC_DIR = f\"{PROJECT_DIR}/src\"\n","CONFIG_FILE = f\"{PROJECT_DIR}/notebooks/flavio/config.yaml\"\n","OUTPUT_FILE = f\"{PROJECT_DIR}/results/submission.tsv\"\n","\n","sys.path.append(SRC_DIR)\n","\n","# Choose device\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","print(f\"Device: {device}\")\n","\n","# Load the configuration data from the YAML file\n","with open(CONFIG_FILE, 'r') as f:\n","    config_data = yaml.safe_load(f)\n","\n","\n","np.random.seed(42)\n","random.seed(42)"]},{"cell_type":"code","source":["blast_folder = f\"{PROJECT_DIR}/train/blast_results_train\"\n","df_gt = pd.read_csv(f\"{PROJECT_DIR}/train/tsvs/train_set.tsv\", sep='\\t')"],"metadata":{"id":"TeNGN_9wJ9IG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","def create_count_df(df):\n","    # this function is to transform a table with blast results in a table of counts\n","    df = df.explode('GO_term')\n","    df = df.groupby([0, 'GO_term']).size().unstack(fill_value=0)\n","    df.reset_index(inplace=True)\n","    return df\n","\n","def blast_dfs_aspect(df_blast, df_gt, aspect, thresh=0.001):\n","    df_blast = df_blast.drop([2, 4], axis=1)                              # drop useless columns\n","    df_blast = df_blast.loc[df_blast[3] <= thresh]                        # apply evalue threshold\n","    df_blast = df_blast.drop([3], axis=1)                                 # drop useless column\n","    df_blast = df_blast.drop_duplicates(subset=[0, 1])                    # eliminate duplicates (won't count the same coupling more than once)\n","    df_blast = df_blast[df_blast[0] != df_blast[1]]                       # eliminate self alignment (protein with itself)\n","    df_blast = df_blast.merge(df_gt, left_on=1, right_on='Protein_ID', how='left')      # merge with ground truth to get GO annotations\n","    df_blast = df_blast.groupby([0, 'aspect'], as_index=False).agg({'GO_term': lambda x: list(x)})      # groupby aspect\n","    df_blast = df_blast[df_blast['aspect'] == aspect]                     # select aspect of interest\n","    df_blast = df_blast.drop(['aspect'], axis=1)                          # drop aspect column\n","    df_blast = create_count_df(df_blast)                                  # create counts table with counts fo each GO\n","\n","    return df_blast\n"],"metadata":{"id":"WvUIKdz9ATWT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# the following procedure has to be repeated for each aspect\n","chunk = []\n","aspect = 'biological_process'\n","\n","# go through the blast files and get table of counts for each. store each resulting pd in an array\n","for file in os.listdir(blast_folder):\n","    filename = os.fsdecode(file)\n","    print(filename)\n","    if filename.endswith(\".tsv\"):\n","        df_blast = pd.read_csv(f\"{blast_folder}/{filename}\", header=None, sep='\\t')\n","        df_blast = blast_dfs_aspect(df_blast, df_gt, aspect, thresh=0.001)\n","\n","        chunk.append(df_blast)\n","    else:\n","        continue\n","# uncomment when needed. concat chunks stored in array\n","#df_blast_bp_all = pd.concat(chunk, ignore_index=True)\n","#df_blast_mf_all = pd.concat(chunk, ignore_index=True)\n","#df_blast_cc_all = pd.concat(chunk, ignore_index=True)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4lDww9IXR2FO","executionInfo":{"status":"ok","timestamp":1737202278531,"user_tz":-60,"elapsed":447705,"user":{"displayName":"Flavio Agostini","userId":"01513805401167554788"}},"outputId":"2b273a7a-1a33-4622-fee0-52a3be3341cd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train.part_004.tsv\n","train.part_005.tsv\n","train.part_006.tsv\n","train.part_007.tsv\n","train.part_008.tsv\n","train.part_009.tsv\n","train.part_010.tsv\n","train.part_011.tsv\n","train.part_012.tsv\n","train.part_013.tsv\n","train.part_014.tsv\n","train.part_015.tsv\n","train.part_016.tsv\n","train.part_017.tsv\n","train.part_018.tsv\n","train.part_019.tsv\n","train.part_020.tsv\n","train.part_021.tsv\n","train.part_022.tsv\n","train.part_023.tsv\n","train.part_024.tsv\n","train.part_025.tsv\n","train.part_001.tsv\n","train.part_002.tsv\n","train.part_003.tsv\n"]}]},{"cell_type":"code","source":["# save to file\n","combined_df.to_csv('combined_df.tsv', sep='\\t', index=False, header = True)\n","\n","!mkdir blast_dfs\n","!mv 'combined_df.tsv' blast_dfs/\n","!cp -r \"blast_dfs\" \"$PROJECT_DIR/train/\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bt2biQ0vAWKZ","executionInfo":{"status":"ok","timestamp":1737202476901,"user_tz":-60,"elapsed":46111,"user":{"displayName":"Flavio Agostini","userId":"01513805401167554788"}},"outputId":"800bbf2a-a8f4-4361-886a-aec4e626c865"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["mkdir: cannot create directory ‘blast_dfs’: File exists\n"]}]}]}